Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 batch_normalization (BatchN  (None, 32, 32, 3)        12        
 ormalization)                                                   
                                                                 
 Input_layer (Flatten)       (None, 3072)              0         
                                                                 
 Hidden_layer_1 (Dense)      (None, 50)                153650    
                                                                 
 dropout (Dropout)           (None, 50)                0         
                                                                 
 Output_layer (Dense)        (None, 10)                510       
                                                                 
=================================================================
Total params: 154,172
Trainable params: 154,166
Non-trainable params: 6
_________________________________________________________________
Epoch 1/10
1563/1563 [==============================] - 7s 4ms/step - loss: 1.8878 - sparse_categorical_accuracy: 0.3300 - val_loss: 1.7207 - val_sparse_categorical_accuracy: 0.3929
Epoch 2/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.7646 - sparse_categorical_accuracy: 0.3769 - val_loss: 1.6776 - val_sparse_categorical_accuracy: 0.4067
Epoch 3/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.7236 - sparse_categorical_accuracy: 0.3911 - val_loss: 1.6614 - val_sparse_categorical_accuracy: 0.4216
Epoch 4/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.6944 - sparse_categorical_accuracy: 0.4030 - val_loss: 1.6206 - val_sparse_categorical_accuracy: 0.4292
Epoch 5/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.6696 - sparse_categorical_accuracy: 0.4082 - val_loss: 1.6089 - val_sparse_categorical_accuracy: 0.4348
Epoch 6/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.6520 - sparse_categorical_accuracy: 0.4182 - val_loss: 1.5866 - val_sparse_categorical_accuracy: 0.4391
Epoch 7/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.6445 - sparse_categorical_accuracy: 0.4166 - val_loss: 1.5779 - val_sparse_categorical_accuracy: 0.4392
Epoch 8/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.6291 - sparse_categorical_accuracy: 0.4245 - val_loss: 1.5605 - val_sparse_categorical_accuracy: 0.4479
Epoch 9/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.6176 - sparse_categorical_accuracy: 0.4285 - val_loss: 1.5631 - val_sparse_categorical_accuracy: 0.4481
Epoch 10/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.6097 - sparse_categorical_accuracy: 0.4280 - val_loss: 1.5548 - val_sparse_categorical_accuracy: 0.4544
313/313 [==============================] - 0s 1ms/step - loss: 1.5548 - sparse_categorical_accuracy: 0.4544
[[5.6186695e-02 9.8078720e-02 1.4203104e-01 2.0924608e-01 1.3293077e-01
  1.5646917e-01 8.9089468e-02 1.7363036e-02 9.0838075e-02 7.7669946e-03]
 [8.8427097e-02 2.0274130e-01 2.4901011e-03 3.5152512e-03 8.1516133e-04
  2.3771522e-03 1.5138912e-04 1.8047930e-03 2.1306793e-01 4.8460990e-01]
 [1.4413479e-01 1.5879776e-01 5.8704219e-03 5.3516296e-03 9.2991121e-04
  3.1466531e-03 1.0389493e-04 1.4424891e-03 5.4191142e-01 1.3831104e-01]
 [3.8812819e-01 4.8120596e-02 3.6969889e-02 1.4945093e-02 1.3846886e-02
  1.3970710e-02 8.0972631e-04 2.2062201e-02 4.4260499e-01 1.8541742e-02]
 [1.8563826e-02 8.5103642e-03 1.8704861e-01 7.1271002e-02 3.6594638e-01
  6.6823013e-02 1.9919127e-01 6.4022847e-02 1.2530096e-02 6.0925810e-03]]
[3 9 8 8 4 6 5 6 5 1 8 9 5 1 0 8 5 4 8 6]
[3 8 8 0 6 6 1 6 3 1 0 9 5 7 9 8 5 7 8 6]
[[519  34  47  33  40  20  15  48 184  60]
 [ 37 559  20  29  25  25  20  32  66 187]
 [ 97  35 188  65 280  68 127  74  40  26]
 [ 30  31  72 240  97 198 164  63  40  65]
 [ 54  11  77  44 507  45 121  91  31  19]
 [ 24  19  71 166 113 340  99  91  45  32]
 [  5  16  43  90 184  74 522  27  15  24]
 [ 44  30  39  64 125  65  48 483  29  73]
 [100  77  14  20  26  27   8  15 627  86]
 [ 49 165  11  25  12  23  27  57  72 559]]
