Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 batch_normalization (BatchN  (None, 32, 32, 3)        12        
 ormalization)                                                   
                                                                 
 Input_layer (Flatten)       (None, 3072)              0         
                                                                 
 Hidden_layer_1 (Dense)      (None, 50)                153650    
                                                                 
 dropout (Dropout)           (None, 50)                0         
                                                                 
 Hidden_layer_2 (Dense)      (None, 50)                2550      
                                                                 
 dropout_1 (Dropout)         (None, 50)                0         
                                                                 
 Output_layer (Dense)        (None, 10)                510       
                                                                 
=================================================================
Total params: 156,722
Trainable params: 156,716
Non-trainable params: 6
_________________________________________________________________
Epoch 1/10
1563/1563 [==============================] - 7s 4ms/step - loss: 1.9765 - sparse_categorical_accuracy: 0.2801 - val_loss: 1.8030 - val_sparse_categorical_accuracy: 0.3641
Epoch 2/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.8446 - sparse_categorical_accuracy: 0.3381 - val_loss: 1.7370 - val_sparse_categorical_accuracy: 0.3861
Epoch 3/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.7952 - sparse_categorical_accuracy: 0.3584 - val_loss: 1.6914 - val_sparse_categorical_accuracy: 0.4019
Epoch 4/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.7655 - sparse_categorical_accuracy: 0.3656 - val_loss: 1.6621 - val_sparse_categorical_accuracy: 0.4066
Epoch 5/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.7452 - sparse_categorical_accuracy: 0.3739 - val_loss: 1.6511 - val_sparse_categorical_accuracy: 0.4145
Epoch 6/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.7280 - sparse_categorical_accuracy: 0.3824 - val_loss: 1.6459 - val_sparse_categorical_accuracy: 0.4159
Epoch 7/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.7156 - sparse_categorical_accuracy: 0.3861 - val_loss: 1.6194 - val_sparse_categorical_accuracy: 0.4249
Epoch 8/10
1563/1563 [==============================] - 7s 4ms/step - loss: 1.7005 - sparse_categorical_accuracy: 0.3902 - val_loss: 1.6101 - val_sparse_categorical_accuracy: 0.4275
Epoch 9/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.6940 - sparse_categorical_accuracy: 0.3942 - val_loss: 1.6039 - val_sparse_categorical_accuracy: 0.4322
Epoch 10/10
1563/1563 [==============================] - 6s 4ms/step - loss: 1.6813 - sparse_categorical_accuracy: 0.4035 - val_loss: 1.5924 - val_sparse_categorical_accuracy: 0.4360
313/313 [==============================] - 0s 1ms/step - loss: 1.5924 - sparse_categorical_accuracy: 0.4360
[[0.06894294 0.08188447 0.1197226  0.19672523 0.05879076 0.1616013
  0.13554806 0.04549557 0.08946129 0.04182782]
 [0.07590065 0.2539486  0.01416293 0.01652614 0.00953856 0.00644389
  0.00325963 0.01041178 0.2449636  0.36484417]
 [0.15164448 0.22364803 0.0314418  0.01922204 0.01295459 0.01416583
  0.00269196 0.01535416 0.32929745 0.19957967]
 [0.2346047  0.11495528 0.0949095  0.04888716 0.05203305 0.05383138
  0.01218811 0.06255694 0.2447917  0.08124212]
 [0.01316235 0.00243152 0.2029361  0.04787318 0.45249167 0.06711034
  0.13666648 0.07235701 0.003185   0.00178629]]
[3 9 8 8 4 6 3 6 2 1 8 9 6 1 1 8 5 3 8 6]
[3 8 8 0 6 6 1 6 3 1 0 9 5 7 9 8 5 7 8 6]
[[493  47  51  50  13  17  24  62 178  65]
 [ 34 599  11  39   6  21  38  38  62 152]
 [110  43 226  82 135  61 189 101  34  19]
 [ 27  47  71 286  46 185 186  75  31  46]
 [ 53  19 134  64 292  46 203 144  29  16]
 [ 25  36  90 178  55 333 127 102  40  14]
 [  6  22  56 137 103  40 575  26  18  17]
 [ 41  41  45  78  68  66  48 519  23  71]
 [114  92  15  35   5  37  15  23 573  91]
 [ 39 234   6  58   4  14  41  62  78 464]]
